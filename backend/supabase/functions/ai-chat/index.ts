import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { GoogleGenerativeAI } from "https://esm.sh/@google/generative-ai@0.21.0";

// Import cost calculator
import { 
  calculateGeminiCosts, 
  createUsageMetrics,
  type GeminiModel 
} from "../shared/gemini-cost-calculator.ts";
const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type"
};
serve(async (req)=>{
  console.log("üöÄ Edge Function ai-chat iniciada");
  // Handle CORS
  if (req.method === "OPTIONS") {
    return new Response(null, {
      headers: corsHeaders
    });
  }
  try {
    console.log("üì• Requisi√ß√£o recebida");
    const supabase = createClient(Deno.env.get("SUPABASE_URL") ?? "", Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "");
    console.log("‚úÖ Supabase client criado");
    const body = await req.json();
    console.log("üì¶ Body recebido:", JSON.stringify(body));
    const { message, conversationId, userId } = body;
    if (!message || !userId) {
      return new Response(JSON.stringify({
        error: "message e userId s√£o obrigat√≥rios"
      }), {
        status: 400,
        headers: {
          ...corsHeaders,
          "Content-Type": "application/json"
        }
      });
    }
    console.log(`üí¨ Mensagem de usu√°rio ${userId}: ${message.substring(0, 50)}...`);
    
    // Track request start time for metrics
    const requestStartTime = performance.now();
    
    // Check if we're in HML environment to skip rate limiting for testing
    const isHMLEnvironment = Deno.env.get("ENVIRONMENT") === "hml";
    
    if (!isHMLEnvironment) {
      // 1. Verifica rate limiting (only in production)
      console.log("üîç Verificando rate limit...");
      const { data: rateLimitCheck, error: rateLimitError } = await supabase.rpc("check_rate_limit", {
        uid: userId,
        max_messages: 20
      });
      if (rateLimitError) {
        console.error("‚ùå Erro ao verificar rate limit:", rateLimitError);
        throw new Error(`Erro ao verificar rate limit: ${rateLimitError.message}`);
      }
      console.log("üìä Rate limit check resultado:", rateLimitCheck);
      if (rateLimitCheck && rateLimitCheck.length > 0) {
        const { allowed, remaining } = rateLimitCheck[0];
        if (!allowed) {
          console.log(`‚õî Rate limit excedido para usu√°rio ${userId}`);
          return new Response(JSON.stringify({
            error: "Voc√™ atingiu o limite de 20 mensagens por hora. Tente novamente mais tarde.",
            rateLimitExceeded: true
          }), {
            status: 429,
            headers: {
              ...corsHeaders,
              "Content-Type": "application/json"
            }
          });
        }
        console.log(`‚úÖ Rate limit OK. Mensagens restantes: ${remaining}`);
      }
    } else {
      console.log("üß™ Ambiente HML detectado - pulando verifica√ß√£o de rate limit");
    }
    // 2. Busca arquivos processados no Gemini File API
    const { data: cachedFiles, error: cacheError } = await supabase
      .from("gemini_file_cache")
      .select("id, display_name, gemini_name, gemini_uri, gemini_file_state, mime_type")
      .eq("gemini_file_state", "ACTIVE");
      
    if (cacheError) {
      console.error("Erro ao buscar cache:", cacheError);
    }
    
    console.log(`üìö ${cachedFiles?.length || 0} arquivo(s) processados no Gemini`);
    
    // 3. Prepara file parts para o Gemini (usando File API nativo)
    const fileParts = [];
    if (cachedFiles && cachedFiles.length > 0) {
      console.log(`ÔøΩ Preparando file parts para Gemini...`);
      
      for (const file of cachedFiles) {
        if (file.gemini_uri && file.mime_type) {
          // Cria part referenciando arquivo j√° processado no Gemini
          // Estrutura compat√≠vel com Gemini API v0.21.0
          fileParts.push({
            fileData: {
              fileUri: file.gemini_uri,
              mimeType: file.mime_type
            }
          });
          console.log(`‚úÖ File part criado para ${file.display_name}`);
        } else {
          console.warn(`‚ö†Ô∏è Arquivo ${file.display_name} sem gemini_uri v√°lido`);
        }
      }
    }
    // 4. Busca hist√≥rico da conversa (√∫ltimas 10 mensagens)
    let messageHistory = [];
    if (conversationId) {
      const { data, error: historyError } = await supabase.from("messages").select("role, content").eq("conversation_id", conversationId).order("created_at", {
        ascending: true
      }).limit(10);
      if (historyError) {
        console.error("Erro ao buscar hist√≥rico:", historyError);
      } else {
        messageHistory = data || [];
      }
    }
    console.log(`üìú ${messageHistory?.length || 0} mensagens no hist√≥rico`);
    // 5. Monta prompt do sistema
    const systemPrompt = `Voc√™ √© o assistente virtual da Jardulli M√°quinas.

CONTEXTO DA EMPRESA:
- Especializada em m√°quinas agr√≠colas

INSTRU√á√ïES IMPORTANTES:
- Responda APENAS com base nos documentos fornecidos
- Se n√£o souber, seja honesto e diga: "N√£o encontrei essa informa√ß√£o em nossa base de conhecimento"
- Use formata√ß√£o markdown (listas, negrito, t√≠tulos)
- Seja profissional, mas acess√≠vel

FORMATO DA RESPOSTA:
- Use t√≠tulos e subt√≠tulos quando apropriado
- Listas numeradas para etapas/processos
- Listas com marcadores para m√∫ltiplos itens
- **Negrito** para informa√ß√µes importantes
- Par√°grafos curtos e objetivos

ESTILO:
- Evite jarg√µes t√©cnicos desnecess√°rios
- Seja proativo: ofere√ßa informa√ß√µes relacionadas
- Finalize sugerindo se pode ajudar com mais alguma coisa

NUNCA:
- Invente pre√ßos ou condi√ß√µes comerciais
- Garanta coisas que n√£o est√£o nos documentos
- Responda perguntas n√£o relacionadas √† Jardulli`;
    // 6. Inicializa Gemini
    const geminiApiKey = Deno.env.get("GEMINI_API_KEY");
    if (!geminiApiKey) {
      return new Response(JSON.stringify({
        error: "GEMINI_API_KEY n√£o configurada"
      }), {
        status: 500,
        headers: {
          ...corsHeaders,
          "Content-Type": "application/json"
        }
      });
    }
    const genAI = new GoogleGenerativeAI(geminiApiKey);
    const modelName = Deno.env.get("GEMINI_MODEL") || "gemini-2.0-flash-exp";
    const model = genAI.getGenerativeModel({
      model: modelName
    });
    // 7. Monta prompt usando Gemini File API (sem limita√ß√£o de tokens!)
    let systemParts: any[] = [{ text: systemPrompt }];
    
    // Adiciona file parts se existirem arquivos processados
    if (fileParts.length > 0) {
      // File parts s√£o adicionados junto com o texto do sistema
      systemParts = [
        { text: systemPrompt },
        ...fileParts,
        { text: "üìö IMPORTANTE: Use APENAS as informa√ß√µes dos documentos anexados para responder. Se a informa√ß√£o n√£o estiver nos documentos, diga que n√£o encontrou." }
      ];
      console.log(`üìé Incluindo ${fileParts.length} file parts no prompt`);
    } else {
      systemParts.push({ 
        text: "‚ö†Ô∏è Nenhum documento encontrado na base de conhecimento. Informe que a base est√° vazia e pe√ßa para o usu√°rio entrar em contato." 
      });
    }

    const contents = [
      // Sistema - instru√ß√£o inicial + file parts
      {
        role: "user",
        parts: systemParts
      },
      {
        role: "model",
        parts: [{ text: "Entendido! Vou responder apenas com base nos documentos fornecidos." }]
      },
      // Hist√≥rico de mensagens
      ...(messageHistory || []).map((msg)=>({
          role: msg.role === "assistant" ? "model" : "user",
          parts: [
            {
              text: msg.content
            }
          ]
        })),
      // Nova pergunta
      {
        role: "user",
        parts: [
          {
            text: message
          }
        ]
      }
    ];
    console.log(`ü§ñ Chamando Gemini com ${contents.length} mensagens...`);
    console.log(`üìù Contents:`, JSON.stringify(contents, null, 2));
    // 8. Chama Gemini com retry em caso de erro de quota
    let result;
    let retryCount = 0;
    const maxRetries = 3;
    while(retryCount < maxRetries){
      try {
        result = await model.generateContent({
          contents,
          generationConfig: {
            temperature: 0.7,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 1024
          }
        });
        break; // Sucesso, sai do loop
      } catch (error) {
        console.log(`‚ùå Erro na tentativa ${retryCount + 1}:`, error.message);
        // Se √© erro de quota (429), aguarda e tenta novamente
        if (error.message?.includes('429') || error.message?.includes('quota')) {
          retryCount++;
          if (retryCount < maxRetries) {
            const waitTime = Math.pow(2, retryCount) * 1000; // Backoff exponencial
            console.log(`‚è≥ Aguardando ${waitTime}ms antes da pr√≥xima tentativa...`);
            await new Promise((resolve)=>setTimeout(resolve, waitTime));
            continue;
          } else {
            // M√°ximo de tentativas atingido, retorna erro amig√°vel
            return new Response(JSON.stringify({
              success: false,
              error: "Sistema temporariamente ocupado. Por favor, aguarde alguns segundos e tente novamente.",
              details: "Rate limit exceeded - please try again in a few seconds"
            }), {
              status: 429,
              headers: {
                ...corsHeaders,
                "Content-Type": "application/json"
              }
            });
          }
        } else {
          // Outros erros, n√£o tenta novamente
          throw error;
        }
      }
    }
    const response = result.response;
    const aiResponse = response.text() || "Desculpe, n√£o consegui processar sua pergunta. Por favor, tente novamente.";
    console.log(`‚úÖ Resposta gerada: ${aiResponse.substring(0, 100)}...`);

    // Capture metrics for cost tracking
    const requestEndTime = performance.now();
    const requestDuration = Math.round(requestEndTime - requestStartTime);
    
    // Get token usage from response metadata
    const usageMetadata = result.response.usageMetadata;
    const inputTokens = usageMetadata?.promptTokenCount || 0;
    const outputTokens = usageMetadata?.candidatesTokenCount || 0;
    
    console.log(`üìä Token usage - Input: ${inputTokens}, Output: ${outputTokens}, Duration: ${requestDuration}ms`);

    // Calculate costs and create metrics
    let metricsToLog = null;
    try {
      const currentModel = (modelName as GeminiModel) || 'gemini-1.5-flash';
      const costs = calculateGeminiCosts(currentModel, inputTokens, outputTokens);
      
      console.log(`üí∞ Cost calculation - Input: $${costs.inputCost}, Output: $${costs.outputCost}, Total: $${costs.totalCost}`);
      
      metricsToLog = {
        user_id: userId,
        conversation_id: conversationId,
        model_used: currentModel,
        tokens_input: inputTokens,
        tokens_output: outputTokens,
        cost_input_usd: costs.inputCost,
        cost_output_usd: costs.outputCost,
        request_duration_ms: requestDuration,
        files_processed: fileParts.length,
        request_type: 'chat',
        error_occurred: false,
        error_message: null
      };
      
    } catch (costError) {
      console.error("‚ùå Erro ao calcular custos:", costError);
    }

    // 9. Salva mensagens no banco (user + assistant) - apenas se houver conversationId
    if (conversationId) {
      const { error: insertError } = await supabase.from("messages").insert([
        {
          conversation_id: conversationId,
          role: "user",
          content: message
        },
        {
          conversation_id: conversationId,
          role: "assistant",
          content: aiResponse
        }
      ]);
      if (insertError) {
        console.error("Erro ao salvar mensagens:", insertError);
      }
    } else {
      console.warn("‚ö†Ô∏è ConversationId n√£o fornecido, mensagens n√£o foram salvas");
    }
    if (false) {
      console.error("Erro ao salvar mensagens:", null);
    // N√£o retornamos erro aqui pois a resposta foi gerada
    }
    // 10. Incrementa rate limiting (only in production)
    if (!isHMLEnvironment) {
      await supabase.rpc("increment_rate_limit", {
        uid: userId
      });
    } else {
      console.log("üß™ Ambiente HML detectado - pulando incremento de rate limit");
    }
    
    // 11. Log usage metrics for cost tracking
    if (metricsToLog) {
      try {
        console.log("üìä Salvando m√©tricas de custo...");
        
        // For simplicity, especially in testing, we don't require message_id
        const finalMetrics = {
          ...metricsToLog,
          message_id: null, // Will be updated later if needed
          conversation_id: conversationId || null
        };

        console.log("üìä Dados das m√©tricas:", JSON.stringify(finalMetrics, null, 2));

        const { error: metricsError } = await supabase
          .from("gemini_usage_metrics")
          .insert(finalMetrics);

        if (metricsError) {
          console.error("‚ùå Erro ao salvar m√©tricas:", metricsError);
        } else {
          console.log(`‚úÖ M√©tricas salvas com sucesso - Custo: $${metricsToLog.cost_input_usd + metricsToLog.cost_output_usd}`);
        }
      } catch (metricsError) {
        console.error("‚ùå Erro ao processar m√©tricas:", metricsError);
      }
    }
    
    console.log(`üíæ Mensagens salvas, rate limit atualizado e m√©tricas registradas`);
    return new Response(JSON.stringify({
      success: true,
      reply: aiResponse,
      conversationId,
      sourcesCount: cachedFiles?.length || 0
    }), {
      status: 200,
      headers: {
        ...corsHeaders,
        "Content-Type": "application/json"
      }
    });
  } catch (error) {
    console.error("‚ùå Erro completo:", error);
    console.error("‚ùå Stack:", error?.stack);
    console.error("‚ùå Message:", error?.message);
    return new Response(JSON.stringify({
      success: false,
      error: error?.message || "Erro ao processar mensagem",
      details: error?.toString(),
      stack: error?.stack
    }), {
      status: 500,
      headers: {
        ...corsHeaders,
        "Content-Type": "application/json"
      }
    });
  }
});
