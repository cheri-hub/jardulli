# MVP ToDo List - Jardulli Bot Buddy

## üéØ Objetivo do MVP
Criar uma vers√£o funcional do assistente de IA que possa responder perguntas sobre produtos e servi√ßos da Jardulli M√°quinas usando uma base de conhecimento real.

---

## üî¥ CR√çTICO - Essencial para MVP

### 1. Integra√ß√£o com IA/LLM
**Prioridade**: ALTA | **Estimativa**: 8-16h | **LLM Escolhido**: ‚úÖ **Google Gemini**

- [x] Escolher provedor de LLM: **Google Gemini**
- [ ] Obter API key do Google AI Studio (https://makersuite.google.com/app/apikey)
- [ ] Configurar API key no Supabase (vari√°vel de ambiente segura: `GEMINI_API_KEY`)
- [ ] Implementar chamada ao Gemini API em Edge Function
- [ ] Substituir resposta simulada por resposta real
- [ ] Adicionar tratamento de erros da API
- [ ] Implementar retry logic para falhas tempor√°rias
- [ ] Configurar rate limiting para evitar abuso

**Arquivos a modificar**:
- `src/pages/Index.tsx` - remover setTimeout simulado
- Criar: `supabase/functions/chat-completion/index.ts`

**Exemplo de implementa√ß√£o com Google Gemini**:
```typescript
// supabase/functions/chat-completion/index.ts
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"

const GEMINI_API_KEY = Deno.env.get('GEMINI_API_KEY')
const GEMINI_MODEL = 'gemini-1.5-flash' // Ou 'gemini-1.5-pro' para melhor qualidade

serve(async (req) => {
  const { message, conversationHistory } = await req.json()
  
  // Formatar hist√≥rico para Gemini
  const contents = [
    {
      role: 'user',
      parts: [{ text: 'Voc√™ √© um assistente virtual da Jardulli M√°quinas, especializado em caf√© e m√°quinas de caf√©. Seja prestativo, profissional e direto nas respostas.' }]
    },
    {
      role: 'model',
      parts: [{ text: 'Entendido! Estou pronto para ajudar com informa√ß√µes sobre a Jardulli M√°quinas.' }]
    },
    ...conversationHistory.map(msg => ({
      role: msg.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: msg.content }]
    })),
    {
      role: 'user',
      parts: [{ text: message }]
    }
  ]
  
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents,
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        },
        safetySettings: [
          { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_MEDIUM_AND_ABOVE" },
          { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_MEDIUM_AND_ABOVE" },
          { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_MEDIUM_AND_ABOVE" },
          { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_MEDIUM_AND_ABOVE" }
        ]
      })
    }
  )
  
  const data = await response.json()
  
  if (!response.ok) {
    throw new Error(data.error?.message || 'Erro ao chamar Gemini API')
  }
  
  const reply = data.candidates[0]?.content?.parts[0]?.text || 'Desculpe, n√£o consegui gerar uma resposta.'
  
  return new Response(JSON.stringify({ reply }), {
    headers: { 'Content-Type': 'application/json' }
  })
})
```

**Vantagens do Google Gemini**:
- ‚úÖ Excelente custo-benef√≠cio (gratuito at√© 15 req/min)
- ‚úÖ Suporte nativo a multimodal (texto + imagens futuras)
- ‚úÖ Lat√™ncia baixa
- ‚úÖ Modelos: Gemini 1.5 Flash (r√°pido) e Pro (mais capaz)

---

### 2. Base de Conhecimento
**Prioridade**: ALTA | **Estimativa**: 12-24h

#### 2.1 Coleta de Conte√∫do
- [ ] Reunir documenta√ß√£o de produtos da Jardulli
- [ ] Coletar manuais t√©cnicos
- [ ] Compilar FAQs existentes
- [ ] Documentar especifica√ß√µes de m√°quinas
- [ ] Incluir informa√ß√µes de contato e suporte
- [ ] Adicionar pol√≠ticas de garantia e assist√™ncia

#### 2.2 Estrutura√ß√£o da Base
- [ ] Criar tabela `knowledge_base` no Supabase
- [ ] Definir schema para documentos
- [ ] Implementar chunking de documentos grandes
- [ ] Adicionar metadata (categoria, produto, data)

**Schema sugerido**:
```sql
CREATE TABLE knowledge_base (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  category TEXT, -- 'produto', 'servico', 'suporte', 'faq'
  product_name TEXT,
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### 2.3 Vetoriza√ß√£o (RAG - Retrieval Augmented Generation)
- [ ] Instalar extens√£o pgvector no Supabase
- [ ] Criar coluna de embeddings na tabela
- [ ] Implementar fun√ß√£o de gera√ß√£o de embeddings
- [ ] Criar √≠ndice vetorial para busca eficiente
- [ ] Implementar busca sem√¢ntica

**Implementa√ß√£o com Gemini Embeddings**:
```sql
-- Habilitar extens√£o
CREATE EXTENSION IF NOT EXISTS vector;

-- Adicionar coluna de embeddings
ALTER TABLE knowledge_base 
ADD COLUMN embedding VECTOR(768); -- Gemini text-embedding-004 usa 768 dimens√µes

-- Criar √≠ndice
CREATE INDEX ON knowledge_base 
USING ivfflat (embedding vector_cosine_ops);

-- Fun√ß√£o de busca
CREATE FUNCTION search_knowledge(
  query_embedding VECTOR(768),
  match_threshold FLOAT,
  match_count INT
)
RETURNS TABLE (
  id UUID,
  content TEXT,
  similarity FLOAT
)
LANGUAGE SQL STABLE
AS $$
  SELECT id, content,
    1 - (embedding <=> query_embedding) AS similarity
  FROM knowledge_base
  WHERE 1 - (embedding <=> query_embedding) > match_threshold
  ORDER BY similarity DESC
  LIMIT match_count;
$$;
```

**Edge Function para gerar embeddings com Gemini**:
```typescript
// supabase/functions/generate-embeddings/index.ts
const GEMINI_API_KEY = Deno.env.get('GEMINI_API_KEY')

async function generateEmbedding(text: string) {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=${GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: "models/text-embedding-004",
        content: { parts: [{ text }] }
      })
    }
  )
  
  const data = await response.json()
  return data.embedding.values // Array de 768 dimens√µes
}
```

#### 2.4 Pipeline de Ingest√£o
- [ ] Criar Edge Function para processar novos documentos
- [ ] Implementar chunking autom√°tico
- [ ] Gerar embeddings para cada chunk
- [ ] Salvar no banco de dados

---

### 3. Fluxo RAG Completo
**Prioridade**: ALTA | **Estimativa**: 8-12h

- [ ] Implementar busca sem√¢ntica na pergunta do usu√°rio
- [ ] Recuperar top 3-5 chunks mais relevantes
- [ ] Montar contexto para o LLM
- [ ] Enviar contexto + pergunta para LLM
- [ ] Processar e retornar resposta
- [ ] Adicionar cita√ß√µes/fontes na resposta

**Edge Function integrada com Gemini**:
```typescript
// supabase/functions/ai-chat/index.ts
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const GEMINI_API_KEY = Deno.env.get('GEMINI_API_KEY')
const SUPABASE_URL = Deno.env.get('SUPABASE_URL')
const SUPABASE_SERVICE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')

const supabase = createClient(SUPABASE_URL!, SUPABASE_SERVICE_KEY!)

async function generateEmbedding(text: string) {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=${GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: "models/text-embedding-004",
        content: { parts: [{ text }] }
      })
    }
  )
  const data = await response.json()
  return data.embedding.values
}

serve(async (req) => {
  const { message, conversationId } = await req.json()
  
  // 1. Gerar embedding da pergunta
  const embedding = await generateEmbedding(message)
  
  // 2. Buscar contexto relevante na base de conhecimento
  const { data: results } = await supabase.rpc('search_knowledge', {
    query_embedding: embedding,
    match_threshold: 0.7,
    match_count: 5
  })
  
  // 3. Montar contexto
  const context = results?.map(r => r.content).join('\n\n---\n\n') || ''
  
  // 4. Buscar hist√≥rico da conversa
  const { data: messages } = await supabase
    .from('messages')
    .select('role, content')
    .eq('conversation_id', conversationId)
    .order('created_at', { ascending: true })
    .limit(10)
  
  // 5. Montar prompt com contexto
  const systemPrompt = `Voc√™ √© o assistente virtual da Jardulli M√°quinas, especializado em caf√© e equipamentos.

BASE DE CONHECIMENTO:
${context}

INSTRU√á√ïES:
- Use APENAS as informa√ß√µes da base de conhecimento acima
- Se n√£o souber a resposta, diga claramente e sugira contato: (19) 98212-1616
- Seja profissional, prestativo e objetivo
- Responda em portugu√™s brasileiro`

  // 6. Chamar Gemini
  const contents = [
    { role: 'user', parts: [{ text: systemPrompt }] },
    { role: 'model', parts: [{ text: 'Entendido! Vou usar apenas a base de conhecimento fornecida.' }] },
    ...messages.map(msg => ({
      role: msg.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: msg.content }]
    })),
    { role: 'user', parts: [{ text: message }] }
  ]
  
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents,
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        }
      })
    }
  )
  
  const data = await response.json()
  const reply = data.candidates[0]?.content?.parts[0]?.text || 
    'Desculpe, n√£o consegui processar sua pergunta. Tente novamente.'
  
  return new Response(JSON.stringify({ 
    reply,
    sources: results?.length || 0 
  }), {
    headers: { 'Content-Type': 'application/json' }
  })
})
```

---

### 4. Interface de Usu√°rio - Melhorias Cr√≠ticas
**Prioridade**: M√âDIA | **Estimativa**: 4-6h

- [ ] Adicionar indicador de "IA est√° pensando..."
- [ ] Mostrar fontes/refer√™ncias usadas na resposta
- [ ] Implementar streaming de resposta (texto aparecendo progressivamente)
- [ ] Adicionar bot√£o "Parar gera√ß√£o" durante streaming
- [ ] Melhorar feedback visual de erros
- [ ] Adicionar mensagem de boas-vindas explicativa

**Exemplo de mensagem inicial**:
```
üëã Ol√°! Sou o assistente virtual da Jardulli M√°quinas.

Posso ajud√°-lo com:
‚Ä¢ Informa√ß√µes sobre nossos produtos
‚Ä¢ Especifica√ß√µes t√©cnicas
‚Ä¢ Suporte e manuten√ß√£o
‚Ä¢ Perguntas frequentes
‚Ä¢ Contato e localiza√ß√£o

Como posso ajudar voc√™ hoje?
```

---

### 5. Tratamento de Erros
**Prioridade**: ALTA | **Estimativa**: 3-4h

- [ ] Implementar fallback quando IA n√£o sabe responder
- [ ] Adicionar timeout para requisi√ß√µes longas (30s)
- [ ] Tratar erros de API (rate limit, quota, etc)
- [ ] Mostrar mensagem amig√°vel ao usu√°rio
- [ ] Log de erros para an√°lise posterior
- [ ] Implementar retry autom√°tico (1-2 tentativas)

**Mensagens de fallback**:
```typescript
const FALLBACK_MESSAGES = {
  noContext: "Desculpe, n√£o encontrei informa√ß√µes espec√≠ficas sobre isso. Posso te direcionar para nosso suporte: (19) 98212-1616",
  apiError: "Ops! Tive um problema tempor√°rio. Por favor, tente novamente.",
  timeout: "A resposta est√° demorando mais que o esperado. Tente reformular sua pergunta.",
}
```

---

## üü° IMPORTANTE - Recomendado para MVP

### 6. Hist√≥rico de Conversas
**Prioridade**: M√âDIA | **Estimativa**: 4-6h

- [ ] Implementar contexto de conversa (√∫ltimas 5-10 mensagens)
- [ ] Enviar hist√≥rico para LLM para respostas contextualizadas
- [ ] Limitar tokens do hist√≥rico (max 4000 tokens)
- [ ] Adicionar bot√£o "Limpar contexto" se conversa ficar confusa

---

### 7. Melhorias no Feedback
**Prioridade**: M√âDIA | **Estimativa**: 2-3h

- [ ] Adicionar campo "Por que este feedback?" (dropdown)
  - Resposta incorreta
  - Informa√ß√£o desatualizada
  - N√£o entendeu a pergunta
  - Resposta incompleta
  - Outro
- [ ] Salvar feedback para treinar/melhorar sistema
- [ ] Dashboard admin para revisar feedbacks (futuro)

---

### 8. Valida√ß√£o e Seguran√ßa
**Prioridade**: ALTA | **Estimativa**: 3-4h

- [ ] Implementar rate limiting por usu√°rio (ex: 20 msgs/hora)
- [ ] Adicionar valida√ß√£o de tamanho da mensagem (max 1000 chars)
- [ ] Sanitizar inputs para evitar prompt injection
- [ ] Implementar modera√ß√£o de conte√∫do (palavr√µes, spam)
- [ ] Adicionar CAPTCHA ou similar se necess√°rio

**Implementa√ß√£o de rate limiting**:
```sql
-- Tabela para rate limiting
CREATE TABLE user_rate_limit (
  user_id UUID PRIMARY KEY REFERENCES auth.users(id),
  message_count INT DEFAULT 0,
  window_start TIMESTAMPTZ DEFAULT NOW(),
  CONSTRAINT check_limit CHECK (message_count <= 20)
);

-- Fun√ß√£o para verificar limite
CREATE FUNCTION check_rate_limit(uid UUID)
RETURNS BOOLEAN AS $$
DECLARE
  current_count INT;
  window_start TIMESTAMPTZ;
BEGIN
  SELECT message_count, window_start 
  INTO current_count, window_start
  FROM user_rate_limit WHERE user_id = uid;
  
  -- Reset se passou 1 hora
  IF window_start < NOW() - INTERVAL '1 hour' THEN
    UPDATE user_rate_limit 
    SET message_count = 1, window_start = NOW()
    WHERE user_id = uid;
    RETURN TRUE;
  END IF;
  
  -- Incrementar contador
  IF current_count < 20 THEN
    UPDATE user_rate_limit 
    SET message_count = message_count + 1
    WHERE user_id = uid;
    RETURN TRUE;
  END IF;
  
  RETURN FALSE;
END;
$$ LANGUAGE plpgsql;
```

---

### 9. Testes B√°sicos
**Prioridade**: M√âDIA | **Estimativa**: 6-8h

- [ ] Criar conjunto de perguntas de teste
- [ ] Testar com diferentes usu√°rios
- [ ] Validar qualidade das respostas
- [ ] Testar edge cases (mensagens muito longas, caracteres especiais)
- [ ] Testar fluxo de feedback
- [ ] Testar compartilhamento

**Perguntas de teste sugeridas**:
```
1. "Quais m√°quinas voc√™s t√™m para caf√©?"
2. "Qual a garantia dos produtos?"
3. "Como entrar em contato?"
4. "Pre√ßo da m√°quina X"
5. "Voc√™s fazem manuten√ß√£o?"
6. "Hor√°rio de atendimento"
7. "Onde fica a loja?"
8. [pergunta fora do contexto] "Qual a capital da Fran√ßa?"
```

---

### 10. Otimiza√ß√µes de Performance
**Prioridade**: BAIXA | **Estimativa**: 3-4h

- [ ] Implementar cache de respostas frequentes
- [ ] Otimizar queries do banco de dados
- [ ] Adicionar √≠ndices necess√°rios
- [ ] Implementar lazy loading de conversas antigas
- [ ] Comprimir payloads da API

---

## üü¢ NICE TO HAVE - Melhorias Futuras

### 11. Analytics B√°sico
**Prioridade**: BAIXA | **Estimativa**: 4-6h

- [ ] Criar tabela `analytics_events`
- [ ] Rastrear perguntas mais frequentes
- [ ] Medir tempo m√©dio de resposta
- [ ] Calcular taxa de satisfa√ß√£o (feedbacks positivos/negativos)
- [ ] Dashboard simples de m√©tricas

---

### 12. Recursos Adicionais
**Prioridade**: BAIXA | **Estimativa**: Vari√°vel

- [ ] Sugest√µes de perguntas relacionadas
- [ ] Bot√µes de a√ß√£o r√°pida (ex: "Falar com humano")
- [ ] Exportar conversa como PDF
- [ ] Busca em conversas antigas
- [ ] Notifica√ß√µes de novas funcionalidades
- [ ] Tutorial de primeiro uso

---

## üìã Checklist de Deploy do MVP

### Pr√©-Deploy
- [ ] Obter API key do Google AI Studio (https://makersuite.google.com/app/apikey)
- [ ] Configurar vari√°veis de ambiente no Supabase:
  - `GEMINI_API_KEY`
  - `SUPABASE_URL`
  - `SUPABASE_SERVICE_ROLE_KEY`
- [ ] Base de conhecimento populada e vetorizada
- [ ] Testes de integra√ß√£o passando
- [ ] Rate limiting configurado
- [ ] Tratamento de erros implementado

### Deploy
- [ ] Fazer backup do banco de dados
- [ ] Executar migrations no Supabase
- [ ] Deploy das Edge Functions
- [ ] Deploy do frontend (Lovable/Vercel/Netlify)
- [ ] Configurar dom√≠nio customizado (se aplic√°vel)
- [ ] Configurar SSL/HTTPS

### P√≥s-Deploy
- [ ] Testar fluxo completo em produ√ß√£o
- [ ] Verificar logs de erro
- [ ] Monitorar uso de API (custos)
- [ ] Testar com usu√°rios beta (2-3 pessoas)
- [ ] Coletar feedback inicial
- [ ] Ajustar prompts se necess√°rio

---

## üí∞ Estimativa de Custos (Mensal)

### Google Gemini API ‚úÖ
**Tier Gratuito (Free tier)**:
- **Gemini 1.5 Flash**: 15 requisi√ß√µes/minuto GRATUITO
- **Gemini 1.5 Pro**: 2 requisi√ß√µes/minuto GRATUITO
- **Text Embeddings**: 1500 requisi√ß√µes/dia GRATUITO
- Perfeito para MVP e pequena escala!

**Tier Pago** (se necess√°rio expans√£o):
- **Gemini 1.5 Flash**: 
  - Input: $0.075 / 1M tokens
  - Output: $0.30 / 1M tokens
- **Gemini 1.5 Pro**:
  - Input: $1.25 / 1M tokens
  - Output: $5.00 / 1M tokens
- **Text Embeddings**: $0.00001 / 1K tokens

**Estimativa para 1000 conversas/m√™s**:
- **Tier Gratuito**: $0 (dentro dos limites!)
- **Se pago (Flash)**: ~$2-5/m√™s
- **Se pago (Pro)**: ~$10-20/m√™s

### Supabase
- **Free tier**: Suficiente para MVP (500MB database, 2GB bandwidth)
- **Pro** ($25/m√™s): Recomendado ap√≥s 100+ usu√°rios ativos

### Total Estimado
- **MVP inicial**: **$0/m√™s** üéâ (usando tier gratuito Gemini + Supabase Free)
- **Pequena escala** (at√© ~500 usu√°rios): $0-10/m√™s
- **Produ√ß√£o** (ap√≥s crescimento): $25-50/m√™s (Supabase Pro + Gemini pago)

**Vantagem do Gemini**: Come√ßar completamente GRATUITO!

---

## üéØ Ordem de Implementa√ß√£o Sugerida

### Sprint 1 (Semana 1) - Funda√ß√£o
1. Coletar e estruturar base de conhecimento
2. Criar schema de banco de dados
3. Configurar pgvector

### Sprint 2 (Semana 2) - IA Core
4. Implementar Edge Function de IA
5. Integrar com LLM escolhido
6. Implementar vetoriza√ß√£o e RAG

### Sprint 3 (Semana 3) - Refinamentos
7. Melhorar UI/UX
8. Implementar tratamento de erros
9. Adicionar rate limiting

### Sprint 4 (Semana 4) - Testes e Deploy
10. Testes completos
11. Ajustes de prompts
12. Deploy para produ√ß√£o
13. Coleta de feedback

---

## üìù Documenta√ß√£o Adicional Necess√°ria

- [ ] README atualizado com setup completo
- [ ] Guia de contribui√ß√£o
- [ ] Documenta√ß√£o de API das Edge Functions
- [ ] Guia de troubleshooting
- [ ] Processo de atualiza√ß√£o da base de conhecimento
- [ ] Manual do administrador

---

## üö® Riscos e Mitiga√ß√µes

| Risco | Impacto | Probabilidade | Mitiga√ß√£o |
|-------|---------|---------------|-----------|
| Custo de API muito alto | Alto | M√©dia | Implementar cache, usar GPT-3.5, rate limiting |
| Respostas de baixa qualidade | Alto | M√©dia | Melhorar prompts, aumentar base de conhecimento |
| Performance lenta | M√©dio | Baixa | Otimizar queries, adicionar √≠ndices, cache |
| Abuso do sistema | M√©dio | M√©dia | Rate limiting, captcha, modera√ß√£o |
| Base de conhecimento desatualizada | M√©dio | Alta | Processo de atualiza√ß√£o peri√≥dica |

---

## üìû Pr√≥ximos Passos Imediatos

1. ‚úÖ **Provedor de LLM definido**: **Google Gemini** (custo zero para come√ßar!)
2. **Obter API key**: Acessar https://makersuite.google.com/app/apikey
3. **Reunir equipe da Jardulli** para coletar conte√∫do da base de conhecimento
4. **Criar primeira vers√£o da base de conhecimento** (mesmo que pequena - 10-20 documentos)
5. **Implementar integra√ß√£o b√°sica** com Gemini API
6. **Testar primeira pergunta e resposta** real
7. **Vetorizar base de conhecimento** usando Gemini Embeddings

---

**√öltima atualiza√ß√£o**: Outubro 2025  
**Status**: Planejamento  
**Respons√°vel**: [Definir]  
**Prazo MVP**: [Definir - sugest√£o: 3-4 semanas]
